{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e79d676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df4765b",
   "metadata": {},
   "source": [
    "### Getting Weather data from https://www.visualcrossing.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "baa38db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Call 1: Fetching weather data for January 2022 (2022-01-01 to 2022-01-31)\n",
      "API Call 2: Fetching weather data for February 2022 (2022-02-01 to 2022-02-28)\n",
      "API Call 3: Fetching weather data for March 2022 (2022-03-01 to 2022-03-31)\n",
      "API Call 4: Fetching weather data for April 2022 (2022-04-01 to 2022-04-30)\n",
      "API Call 5: Fetching weather data for May 2022 (2022-05-01 to 2022-05-31)\n",
      "API Call 6: Fetching weather data for June 2022 (2022-06-01 to 2022-06-30)\n",
      "API Call 7: Fetching weather data for July 2022 (2022-07-01 to 2022-07-31)\n",
      "API Call 8: Fetching weather data for August 2022 (2022-08-01 to 2022-08-31)\n",
      "API Call 9: Fetching weather data for September 2022 (2022-09-01 to 2022-09-30)\n",
      "Weather data fetched successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Replace with your Visual Crossing API key.\n",
    "api_key = 'SJ5FS2UBQXRHR8N846Q3PMPT2' \n",
    "location = 'London,UK'\n",
    "unit_group = 'metric'\n",
    "content_type = 'json'\n",
    "\n",
    "# Define the overall date range\n",
    "start_date_str = '2022-01-01'\n",
    "end_date_str = '2022-09-30'\n",
    "start_date = pd.to_datetime(start_date_str)\n",
    "end_date = pd.to_datetime(end_date_str)\n",
    "\n",
    "# Create a list of start dates for each month (Month Start)\n",
    "monthly_starts = pd.date_range(start_date, end_date, freq='MS')\n",
    "\n",
    "# Container for all hourly records\n",
    "all_hourly_records = []\n",
    "\n",
    "# Counter for API calls\n",
    "api_call_counter = 0\n",
    "\n",
    "# Loop over each month. For each start, end at the day before next month's start.\n",
    "for i in range(len(monthly_starts)):\n",
    "    chunk_start = monthly_starts[i]\n",
    "    # For the last month, set chunk_end to the overall end_date\n",
    "    if i < len(monthly_starts) - 1:\n",
    "        chunk_end = monthly_starts[i+1] - pd.Timedelta(days=1)\n",
    "    else:\n",
    "        chunk_end = end_date\n",
    "    \n",
    "    # Format dates as required by the API (YYYY-MM-DD)\n",
    "    chunk_start_str = chunk_start.strftime('%Y-%m-%d')\n",
    "    chunk_end_str = chunk_end.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Increase API counter\n",
    "    api_call_counter += 1\n",
    "    \n",
    "    # Print a counter with month and year being processed\n",
    "    month_year_str = chunk_start.strftime('%B %Y')\n",
    "    print(f\"API Call {api_call_counter}: Fetching weather data for {month_year_str} ({chunk_start_str} to {chunk_end_str})\")\n",
    "    \n",
    "    # Build the API URL for this monthly chunk:\n",
    "    url = (\n",
    "        f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/\"\n",
    "        f\"{location}/{chunk_start_str}/{chunk_end_str}\"\n",
    "    )\n",
    "    \n",
    "    params = {\n",
    "        'unitGroup': unit_group,\n",
    "        'key': api_key,\n",
    "        'contentType': content_type,\n",
    "        'include': 'hours'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Loop through each day in the response\n",
    "        for day in data.get('days', []):\n",
    "            date_str = day['datetime']  # e.g., \"2023-01-01\"\n",
    "            for hour in day.get('hours', []):\n",
    "                # Construct a full datetime string for conversion.\n",
    "                timestamp_str = f\"{date_str} {hour['datetime']}\"\n",
    "                try:\n",
    "                    full_timestamp = pd.to_datetime(timestamp_str)\n",
    "                except Exception as e:\n",
    "                    print(\"Timestamp conversion error:\", e)\n",
    "                    continue\n",
    "                hourly_record = {\n",
    "                    'DateTime': full_timestamp,\n",
    "                    't1': hour.get('temp'),\n",
    "                    't2': hour.get('feelslike'),\n",
    "                    'hum': hour.get('humidity'),\n",
    "                    'wind_speed': hour.get('windspeed'),\n",
    "                    'weather': hour.get('conditions')\n",
    "                }\n",
    "                all_hourly_records.append(hourly_record)\n",
    "    else:\n",
    "        print(f\"Error fetching weather data: {response.status_code} - {response.text} - for period {chunk_start_str} to {chunk_end_str}\")\n",
    "\n",
    "# Create a DataFrame from the collected hourly records\n",
    "weather_df_2022_p1 = pd.DataFrame(all_hourly_records)\n",
    "print(\"Weather data fetched successfully!\")\n",
    "# print(weather_df_2022_p1.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e62be0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Call 1: Fetching weather data for October 2022 (2022-10-01 to 2022-10-31)\n",
      "API Call 2: Fetching weather data for November 2022 (2022-11-01 to 2022-11-30)\n",
      "API Call 3: Fetching weather data for December 2022 (2022-12-01 to 2022-12-31)\n",
      "Weather data fetched successfully!\n"
     ]
    }
   ],
   "source": [
    "# Replace with your Visual Crossing API key.\n",
    "api_key = 'UHQYZX6RRQQNRZM9PW9V5R738' \n",
    "location = 'London,UK'\n",
    "unit_group = 'metric'\n",
    "content_type = 'json'\n",
    "\n",
    "# Define the overall date range\n",
    "start_date_str = '2022-09-30'\n",
    "end_date_str = '2022-12-31'\n",
    "start_date = pd.to_datetime(start_date_str)\n",
    "end_date = pd.to_datetime(end_date_str)\n",
    "\n",
    "# Create a list of start dates for each month (Month Start)\n",
    "monthly_starts = pd.date_range(start_date, end_date, freq='MS')\n",
    "\n",
    "# Container for all hourly records\n",
    "all_hourly_records = []\n",
    "\n",
    "# Counter for API calls\n",
    "api_call_counter = 0\n",
    "\n",
    "# Loop over each month. For each start, end at the day before next month's start.\n",
    "for i in range(len(monthly_starts)):\n",
    "    chunk_start = monthly_starts[i]\n",
    "    # For the last month, set chunk_end to the overall end_date\n",
    "    if i < len(monthly_starts) - 1:\n",
    "        chunk_end = monthly_starts[i+1] - pd.Timedelta(days=1)\n",
    "    else:\n",
    "        chunk_end = end_date\n",
    "    \n",
    "    # Format dates as required by the API (YYYY-MM-DD)\n",
    "    chunk_start_str = chunk_start.strftime('%Y-%m-%d')\n",
    "    chunk_end_str = chunk_end.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Increase API counter\n",
    "    api_call_counter += 1\n",
    "    \n",
    "    # Print a counter with month and year being processed\n",
    "    month_year_str = chunk_start.strftime('%B %Y')\n",
    "    print(f\"API Call {api_call_counter}: Fetching weather data for {month_year_str} ({chunk_start_str} to {chunk_end_str})\")\n",
    "    \n",
    "    # Build the API URL for this monthly chunk:\n",
    "    url = (\n",
    "        f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/\"\n",
    "        f\"{location}/{chunk_start_str}/{chunk_end_str}\"\n",
    "    )\n",
    "    \n",
    "    params = {\n",
    "        'unitGroup': unit_group,\n",
    "        'key': api_key,\n",
    "        'contentType': content_type,\n",
    "        'include': 'hours'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Loop through each day in the response\n",
    "        for day in data.get('days', []):\n",
    "            date_str = day['datetime']  # e.g., \"2023-01-01\"\n",
    "            for hour in day.get('hours', []):\n",
    "                # Construct a full datetime string for conversion.\n",
    "                timestamp_str = f\"{date_str} {hour['datetime']}\"\n",
    "                try:\n",
    "                    full_timestamp = pd.to_datetime(timestamp_str)\n",
    "                except Exception as e:\n",
    "                    print(\"Timestamp conversion error:\", e)\n",
    "                    continue\n",
    "                hourly_record = {\n",
    "                    'DateTime': full_timestamp,\n",
    "                    't1': hour.get('temp'),\n",
    "                    't2': hour.get('feelslike'),\n",
    "                    'hum': hour.get('humidity'),\n",
    "                    'wind_speed': hour.get('windspeed'),\n",
    "                    'weather': hour.get('conditions')\n",
    "                }\n",
    "                all_hourly_records.append(hourly_record)\n",
    "    else:\n",
    "        print(f\"Error fetching weather data: {response.status_code} - {response.text} - for period {chunk_start_str} to {chunk_end_str}\")\n",
    "\n",
    "# Create a DataFrame from the collected hourly records\n",
    "weather_df_2022_p2 = pd.DataFrame(all_hourly_records)\n",
    "print(\"Weather data fetched successfully!\")\n",
    "# print(weather_df_2022_p1.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "492d1cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 weather data for both parts combined successfully!\n",
      "Combined weather data saved to 'london_weather_2022.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- Append 2024 p2 Data to Existing 2024 p1 Weather Data --- #\n",
    "weather_df_2022 = pd.concat([weather_df_2022_p1, weather_df_2022_p2], ignore_index=True)\n",
    "print(\"2022 weather data for both parts combined successfully!\") \n",
    "\n",
    "# save the combined DataFrame to CSV for later use\n",
    "combined_file_2022 = 'london_weather_2022.csv'\n",
    "weather_df_2022.to_csv(combined_file_2022, index=False)\n",
    "print(f\"Combined weather data saved to '{combined_file_2022}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4698b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Replace with your Visual Crossing API key.\n",
    "api_key = 'B6885K5WTJVSA45FT8CJEPSYV' \n",
    "location = 'London,UK'\n",
    "unit_group = 'metric'\n",
    "content_type = 'json'\n",
    "\n",
    "# Define the overall date range\n",
    "start_date_str = '2023-01-01'\n",
    "end_date_str = '2023-12-31'\n",
    "start_date = pd.to_datetime(start_date_str)\n",
    "end_date = pd.to_datetime(end_date_str)\n",
    "\n",
    "# Create a list of start dates for each month (Month Start)\n",
    "monthly_starts = pd.date_range(start_date, end_date, freq='MS')\n",
    "\n",
    "# Container for all hourly records\n",
    "all_hourly_records = []\n",
    "\n",
    "# Counter for API calls\n",
    "api_call_counter = 0\n",
    "\n",
    "# Loop over each month. For each start, end at the day before next month's start.\n",
    "for i in range(len(monthly_starts)):\n",
    "    chunk_start = monthly_starts[i]\n",
    "    # For the last month, set chunk_end to the overall end_date\n",
    "    if i < len(monthly_starts) - 1:\n",
    "        chunk_end = monthly_starts[i+1] - pd.Timedelta(days=1)\n",
    "    else:\n",
    "        chunk_end = end_date\n",
    "    \n",
    "    # Format dates as required by the API (YYYY-MM-DD)\n",
    "    chunk_start_str = chunk_start.strftime('%Y-%m-%d')\n",
    "    chunk_end_str = chunk_end.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Increase API counter\n",
    "    api_call_counter += 1\n",
    "    \n",
    "    # Print a counter with month and year being processed\n",
    "    month_year_str = chunk_start.strftime('%B %Y')\n",
    "    print(f\"API Call {api_call_counter}: Fetching weather data for {month_year_str} ({chunk_start_str} to {chunk_end_str})\")\n",
    "    \n",
    "    # Build the API URL for this monthly chunk:\n",
    "    url = (\n",
    "        f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/\"\n",
    "        f\"{location}/{chunk_start_str}/{chunk_end_str}\"\n",
    "    )\n",
    "    \n",
    "    params = {\n",
    "        'unitGroup': unit_group,\n",
    "        'key': api_key,\n",
    "        'contentType': content_type,\n",
    "        'include': 'hours'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Loop through each day in the response\n",
    "        for day in data.get('days', []):\n",
    "            date_str = day['datetime']  # e.g., \"2023-01-01\"\n",
    "            for hour in day.get('hours', []):\n",
    "                # Construct a full datetime string for conversion.\n",
    "                timestamp_str = f\"{date_str} {hour['datetime']}\"\n",
    "                try:\n",
    "                    full_timestamp = pd.to_datetime(timestamp_str)\n",
    "                except Exception as e:\n",
    "                    print(\"Timestamp conversion error:\", e)\n",
    "                    continue\n",
    "                hourly_record = {\n",
    "                    'DateTime': full_timestamp,\n",
    "                    't1': hour.get('temp'),\n",
    "                    't2': hour.get('feelslike'),\n",
    "                    'hum': hour.get('humidity'),\n",
    "                    'wind_speed': hour.get('windspeed'),\n",
    "                    'weather': hour.get('conditions')\n",
    "                }\n",
    "                all_hourly_records.append(hourly_record)\n",
    "    else:\n",
    "        print(f\"Error fetching weather data: {response.status_code} - {response.text} - for period {chunk_start_str} to {chunk_end_str}\")\n",
    "\n",
    "# Create a DataFrame from the collected hourly records\n",
    "weather_df = pd.DataFrame(all_hourly_records)\n",
    "print(\"Weather data fetched successfully!\")\n",
    "print(weather_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7adfca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV for future reference\n",
    "weather_df.to_csv('london_weather_2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950a0323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Fetch 2024 Weather Data --- #\n",
    "api_key = 'UHQYZX6RRQQNRZM9PW9V5R738'  # Replace with your Visual Crossing API key\n",
    "location = 'London,UK'\n",
    "unit_group = 'metric'\n",
    "content_type = 'json'\n",
    "\n",
    "# Define the date range for 2024\n",
    "start_date_str = '2024-01-01'\n",
    "end_date_str = '2024-10-31'\n",
    "start_date = pd.to_datetime(start_date_str)\n",
    "end_date = pd.to_datetime(end_date_str)\n",
    "\n",
    "# Generate monthly starting dates for 2024\n",
    "monthly_starts = pd.date_range(start_date, end_date, freq='MS')\n",
    "\n",
    "# Container for all hourly records for 2024\n",
    "all_hourly_records_2024_p1 = []\n",
    "\n",
    "# Counter for API calls\n",
    "api_call_counter = 0\n",
    "\n",
    "# Loop over each month in 2024\n",
    "for i in range(len(monthly_starts)):\n",
    "    chunk_start = monthly_starts[i]\n",
    "    # For the last month, set chunk_end to overall end_date; otherwise one day before the next month starts\n",
    "    if i < len(monthly_starts) - 1:\n",
    "        chunk_end = monthly_starts[i+1] - pd.Timedelta(days=1)\n",
    "    else:\n",
    "        chunk_end = end_date\n",
    "\n",
    "    # Format dates for the API call\n",
    "    chunk_start_str = chunk_start.strftime('%Y-%m-%d')\n",
    "    chunk_end_str = chunk_end.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Increment and print the API call counter with month and year info\n",
    "    api_call_counter += 1\n",
    "    month_year_str = chunk_start.strftime('%B %Y')\n",
    "    print(f\"API Call {api_call_counter}: Fetching weather data for {month_year_str} ({chunk_start_str} to {chunk_end_str})\")\n",
    "    \n",
    "    # Build the API URL for the monthly chunk\n",
    "    url = (\n",
    "        f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/\"\n",
    "        f\"{location}/{chunk_start_str}/{chunk_end_str}\"\n",
    "    )\n",
    "    \n",
    "    params = {\n",
    "        'unitGroup': unit_group,\n",
    "        'key': api_key,\n",
    "        'contentType': content_type,\n",
    "        'include': 'hours'  # Ensure that we get hourly data\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        for day in data.get('days', []):\n",
    "            date_str = day['datetime']  # e.g., \"2024-01-01\"\n",
    "            for hour in day.get('hours', []):\n",
    "                # Construct a full datetime string: \"date hour\"\n",
    "                timestamp_str = f\"{date_str} {hour['datetime']}\"\n",
    "                try:\n",
    "                    full_timestamp = pd.to_datetime(timestamp_str)\n",
    "                except Exception as e:\n",
    "                    print(\"Timestamp conversion error:\", e)\n",
    "                    continue\n",
    "                hourly_record = {\n",
    "                    'DateTime': full_timestamp,\n",
    "                    't1': hour.get('temp'),\n",
    "                    't2': hour.get('feelslike'),\n",
    "                    'hum': hour.get('humidity'),\n",
    "                    'wind_speed': hour.get('windspeed'),\n",
    "                    'weather': hour.get('conditions')\n",
    "                }\n",
    "                all_hourly_records_2024_p1.append(hourly_record)\n",
    "    else:\n",
    "        print(f\"Error fetching weather data: {response.status_code} - {response.text} - for period {chunk_start_str} to {chunk_end_str}\")\n",
    "\n",
    "# Create DataFrame for 2024 weather data\n",
    "weather_df_2024_p1 = pd.DataFrame(all_hourly_records_2024_p1)\n",
    "print(\"2024 part 1 weather data fetched successfully!\")\n",
    "display(weather_df_2024_p1.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef918a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Call 1: Fetching weather data for November 2024 (2024-11-01 to 2024-11-30)\n",
      "API Call 2: Fetching weather data for December 2024 (2024-12-01 to 2024-12-31)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Fetch 2024 Weather Data --- #\n",
    "api_key = 'SJ5FS2UBQXRHR8N846Q3PMPT2'  # Replace with your Visual Crossing API key\n",
    "location = 'London,UK'\n",
    "unit_group = 'metric'\n",
    "content_type = 'json'\n",
    "\n",
    "# Define the date range for 2024\n",
    "start_date_str = '2024-11-01'\n",
    "end_date_str = '2024-12-31'\n",
    "start_date = pd.to_datetime(start_date_str)\n",
    "end_date = pd.to_datetime(end_date_str)\n",
    "\n",
    "# Generate monthly starting dates for 2024\n",
    "monthly_starts = pd.date_range(start_date, end_date, freq='MS')\n",
    "\n",
    "# Container for all hourly records for 2024\n",
    "all_hourly_records_2024_p2 = []\n",
    "\n",
    "# Counter for API calls\n",
    "api_call_counter = 0\n",
    "\n",
    "# Loop over each month in 2024\n",
    "for i in range(len(monthly_starts)):\n",
    "    chunk_start = monthly_starts[i]\n",
    "    # For the last month, set chunk_end to overall end_date; otherwise one day before the next month starts\n",
    "    if i < len(monthly_starts) - 1:\n",
    "        chunk_end = monthly_starts[i+1] - pd.Timedelta(days=1)\n",
    "    else:\n",
    "        chunk_end = end_date\n",
    "\n",
    "    # Format dates for the API call\n",
    "    chunk_start_str = chunk_start.strftime('%Y-%m-%d')\n",
    "    chunk_end_str = chunk_end.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Increment and print the API call counter with month and year info\n",
    "    api_call_counter += 1\n",
    "    month_year_str = chunk_start.strftime('%B %Y')\n",
    "    print(f\"API Call {api_call_counter}: Fetching weather data for {month_year_str} ({chunk_start_str} to {chunk_end_str})\")\n",
    "    \n",
    "    # Build the API URL for the monthly chunk\n",
    "    url = (\n",
    "        f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/\"\n",
    "        f\"{location}/{chunk_start_str}/{chunk_end_str}\"\n",
    "    )\n",
    "    \n",
    "    params = {\n",
    "        'unitGroup': unit_group,\n",
    "        'key': api_key,\n",
    "        'contentType': content_type,\n",
    "        'include': 'hours'  # Ensure that we get hourly data\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        for day in data.get('days', []):\n",
    "            date_str = day['datetime']  # e.g., \"2024-01-01\"\n",
    "            for hour in day.get('hours', []):\n",
    "                # Construct a full datetime string: \"date hour\"\n",
    "                timestamp_str = f\"{date_str} {hour['datetime']}\"\n",
    "                try:\n",
    "                    full_timestamp = pd.to_datetime(timestamp_str)\n",
    "                except Exception as e:\n",
    "                    print(\"Timestamp conversion error:\", e)\n",
    "                    continue\n",
    "                hourly_record = {\n",
    "                    'DateTime': full_timestamp,\n",
    "                    't1': hour.get('temp'),\n",
    "                    't2': hour.get('feelslike'),\n",
    "                    'hum': hour.get('humidity'),\n",
    "                    'wind_speed': hour.get('windspeed'),\n",
    "                    'weather': hour.get('conditions')\n",
    "                }\n",
    "                all_hourly_records_2024_p2.append(hourly_record)\n",
    "    else:\n",
    "        print(f\"Error fetching weather data: {response.status_code} - {response.text} - for period {chunk_start_str} to {chunk_end_str}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d38a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024 weather data fetched successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DateTime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "t1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "t2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hum",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wind_speed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "weather",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1a058daa-f57f-4b64-8783-2e08eaea8280",
       "rows": [
        [
         "0",
         "2024-11-01 00:00:00",
         "13.1",
         "13.1",
         "85.98",
         "3.8",
         "Overcast"
        ],
        [
         "1",
         "2024-11-01 01:00:00",
         "13.0",
         "13.0",
         "86.53",
         "2.7",
         "Overcast"
        ],
        [
         "2",
         "2024-11-01 02:00:00",
         "12.6",
         "12.6",
         "88.81",
         "6.2",
         "Overcast"
        ],
        [
         "3",
         "2024-11-01 03:00:00",
         "12.6",
         "12.6",
         "83.11",
         "5.1",
         "Overcast"
        ],
        [
         "4",
         "2024-11-01 04:00:00",
         "12.3",
         "12.3",
         "79.26",
         "5.2",
         "Overcast"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>hum</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-01 00:00:00</td>\n",
       "      <td>13.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>85.98</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Overcast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-01 01:00:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>86.53</td>\n",
       "      <td>2.7</td>\n",
       "      <td>Overcast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-01 02:00:00</td>\n",
       "      <td>12.6</td>\n",
       "      <td>12.6</td>\n",
       "      <td>88.81</td>\n",
       "      <td>6.2</td>\n",
       "      <td>Overcast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-01 03:00:00</td>\n",
       "      <td>12.6</td>\n",
       "      <td>12.6</td>\n",
       "      <td>83.11</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Overcast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-01 04:00:00</td>\n",
       "      <td>12.3</td>\n",
       "      <td>12.3</td>\n",
       "      <td>79.26</td>\n",
       "      <td>5.2</td>\n",
       "      <td>Overcast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime    t1    t2    hum  wind_speed   weather\n",
       "0 2024-11-01 00:00:00  13.1  13.1  85.98         3.8  Overcast\n",
       "1 2024-11-01 01:00:00  13.0  13.0  86.53         2.7  Overcast\n",
       "2 2024-11-01 02:00:00  12.6  12.6  88.81         6.2  Overcast\n",
       "3 2024-11-01 03:00:00  12.6  12.6  83.11         5.1  Overcast\n",
       "4 2024-11-01 04:00:00  12.3  12.3  79.26         5.2  Overcast"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024 weather data for both parts combined successfully!\n",
      "Combined weather data saved to 'london_weather_2024.csv'\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame for 2024 weather data\n",
    "weather_df_2024_p2 = pd.DataFrame(all_hourly_records_2024_p2)\n",
    "print(\"2024 weather data fetched successfully!\")\n",
    "display(weather_df_2024_p2.head())\n",
    "\n",
    "# --- Append 2024 p2 Data to Existing 2024 p1 Weather Data --- #\n",
    "weather_df_2024 = pd.concat([weather_df_2024_p1, weather_df_2024_p2], ignore_index=True)\n",
    "print(\"2024 weather data for both parts combined successfully!\") \n",
    "\n",
    "# save the combined DataFrame to CSV for later use\n",
    "combined_file_2024 = 'london_weather_2024.csv'\n",
    "weather_df_2024.to_csv(combined_file_2024, index=False)\n",
    "print(f\"Combined weather data saved to '{combined_file_2024}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d9dfe327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing 2023 weather data with 8760 rows.\n",
      "Loaded existing 2022 weather data with 8760 rows.\n",
      "Combined weather data now has 17520 rows.\n"
     ]
    }
   ],
   "source": [
    "# --- Append 2023 Data to Existing 2022 Weather Data --- #\n",
    "\n",
    "# Path to the previously saved 2023 weather data\n",
    "file_2022 = 'london_weather_2022.csv'  \n",
    "file_2023 = 'london_weather_2023.csv'  \n",
    "if (os.path.exists(file_2022) & os.path.exists(file_2023)):\n",
    "    # Load the existing 2023 weather data   \n",
    "    weather_df_2023 = pd.read_csv(file_2023, parse_dates=['DateTime'])\n",
    "    print(f\"Loaded existing 2023 weather data with {len(weather_df_2023)} rows.\")\n",
    "    weather_df_2022 = pd.read_csv(file_2022, parse_dates=['DateTime'])\n",
    "    print(f\"Loaded existing 2022 weather data with {len(weather_df_2022)} rows.\")\n",
    "    \n",
    "    # Concatenate the 2022 and 2023 data\n",
    "    combined_weather_df_partial = pd.concat([weather_df_2022, weather_df_2023], ignore_index=True)\n",
    "    print(f\"Combined weather data now has {len(combined_weather_df_partial)} rows.\")\n",
    "    \n",
    "else:\n",
    "    print(\"No existing 2022 or 2023 weather data file found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "05dc5b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing 2024 weather data with 8760 rows.\n",
      "             DateTime   t1   t2    hum  wind_speed           weather\n",
      "0 2024-01-01 00:00:00  8.6  4.8  77.06        30.2          Overcast\n",
      "1 2024-01-01 01:00:00  8.1  4.3  78.59        28.1          Overcast\n",
      "2 2024-01-01 02:00:00  8.1  4.4  78.04        26.7          Overcast\n",
      "3 2024-01-01 03:00:00  8.3  4.8  77.52        25.7          Overcast\n",
      "4 2024-01-01 04:00:00  8.6  5.1  71.85        26.3  Partially cloudy\n",
      "Combined weather data now has 26304 rows.\n",
      "Combined weather data saved to 'london_weather_2022_2023_2024.csv'\n"
     ]
    }
   ],
   "source": [
    "# --- Append 2024 Data to Existing 2023,2022 Weather Data --- #\n",
    "\n",
    "# Path to the previously saved 2024 weather data\n",
    "file_2024 = 'london_weather_2024.csv'  \n",
    "if os.path.exists(file_2024):\n",
    "    # Load the existing 2023 weather data   \n",
    "    weather_df_2024 = pd.read_csv(file_2024, parse_dates=['DateTime'])\n",
    "    print(f\"Loaded existing 2024 weather data with {len(weather_df_2023)} rows.\")\n",
    "    print(weather_df_2024.head())\n",
    "    \n",
    "    # Concatenate the 2023,2022 and 2024 data\n",
    "    combined_weather_df = pd.concat([combined_weather_df_partial, weather_df_2024], ignore_index=True)\n",
    "    print(f\"Combined weather data now has {len(combined_weather_df)} rows.\")\n",
    "    # save the combined DataFrame to CSV for later use\n",
    "    combined_file = 'london_weather_2022_2023_2024.csv'\n",
    "    combined_weather_df.to_csv(combined_file, index=False)\n",
    "    print(f\"Combined weather data saved to '{combined_file}'\")\n",
    "else:\n",
    "    print(\"No existing 2024 weather data file found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c670aa32",
   "metadata": {},
   "source": [
    "### loading Bus and tube Ridership Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a3aca7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Journeys 2022 - Head:\n",
      "  TravelDate  DayOfWeek  TubeJourneyCount  BusJourneyCount\n",
      "0 2022-01-01   Saturday            973000          1787000\n",
      "1 2022-01-02     Sunday           1119000          2135000\n",
      "2 2022-01-03     Monday           1121000          2413000\n",
      "3 2022-01-04    Tuesday           1491000          3351000\n",
      "4 2022-01-05  Wednesday           1686000          3819000\n",
      "\n",
      "Journeys 2023-2024 - Head:\n",
      "\n",
      "Journey Data Date Range:  2022-01-01 00:00:00 to 2024-12-28 00:00:00\n",
      "Total Number of Rows:  1093\n",
      "  TravelDate  DayOfWeek  TubeJourneyCount  BusJourneyCount\n",
      "0 2022-01-01   Saturday            973000          1787000\n",
      "1 2022-01-02     Sunday           1119000          2135000\n",
      "2 2022-01-03     Monday           1121000          2413000\n",
      "3 2022-01-04    Tuesday           1491000          3351000\n",
      "4 2022-01-05  Wednesday           1686000          3819000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Phase 1: Data Acquisition & Setup ---\n",
    "\n",
    "# Define file paths (update these paths as needed)\n",
    "journey_file_2022 = \"raw-data/Journeys_2022.csv\"\n",
    "journey_file_2023_2024 = \"raw-data/Journeys_2023_2024.csv\"\n",
    "\n",
    "# Load the CSV files\n",
    "df_2022 = pd.read_csv(journey_file_2022)\n",
    "df_2023_2024 = pd.read_csv(journey_file_2023_2024)\n",
    "\n",
    "# Convert the TravelDate from YYYYMMDD to datetime\n",
    "df_2022['TravelDate'] = pd.to_datetime(df_2022['TravelDate'], format='%Y%m%d')\n",
    "df_2023_2024['TravelDate'] = pd.to_datetime(df_2023_2024['TravelDate'], format='%Y%m%d')\n",
    "\n",
    "# Option: Check the first few rows for each dataset\n",
    "print(\"Journeys 2022 - Head:\")\n",
    "print(df_2022.head())\n",
    "print(\"\\nJourneys 2023-2024 - Head:\")\n",
    "# print(df_2023_2024.head())\n",
    "\n",
    "# Combine both datasets into one (assuming they have the same columns)\n",
    "journey_data = pd.concat([df_2022, df_2023_2024], ignore_index=True)\n",
    "\n",
    "# Drop any duplicate rows and sort by TravelDate\n",
    "journey_data = journey_data.drop_duplicates().sort_values('TravelDate').reset_index(drop=True)\n",
    "\n",
    "# Display basic information: Date range and row count\n",
    "print(\"\\nJourney Data Date Range: \", journey_data['TravelDate'].min(), \"to\", journey_data['TravelDate'].max())\n",
    "print(\"Total Number of Rows: \", len(journey_data))\n",
    "\n",
    "# Preview the combined journey data\n",
    "print(journey_data.head())\n",
    "\n",
    "journey_data.to_csv(\"combined-rider-data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fafff9c",
   "metadata": {},
   "source": [
    "### Merge the dataset with weatherdata and create new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d03c123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily weather sample:\n",
      "        Date         t1         t2        hum  wind_speed           weather\n",
      "0 2022-01-01  13.808333  13.808333  82.880417   20.137500  Partially cloudy\n",
      "1 2022-01-02  11.750000  11.516667  83.035833   21.654167  Partially cloudy\n",
      "2 2022-01-03   9.941667   8.645833  81.815000   17.616667  Partially cloudy\n",
      "3 2022-01-04   5.704167   2.900000  83.017917   13.841667  Partially cloudy\n",
      "4 2022-01-05   3.412500   0.066667  76.649167   15.183333             Clear\n",
      "Journey data sample:\n",
      "   TravelDate  DayOfWeek  TubeJourneyCount  BusJourneyCount\n",
      "0  2022-01-01   Saturday            973000          1787000\n",
      "1  2022-01-02     Sunday           1119000          2135000\n",
      "2  2022-01-03     Monday           1121000          2413000\n",
      "3  2022-01-04    Tuesday           1491000          3351000\n",
      "4  2022-01-05  Wednesday           1686000          3819000\n",
      "Journey data sample:\n",
      "  TravelDate  DayOfWeek  TubeJourneyCount  BusJourneyCount\n",
      "0 2022-01-01   Saturday            973000          1787000\n",
      "1 2022-01-02     Sunday           1119000          2135000\n",
      "2 2022-01-03     Monday           1121000          2413000\n",
      "3 2022-01-04    Tuesday           1491000          3351000\n",
      "4 2022-01-05  Wednesday           1686000          3819000\n",
      "Merged daily data sample:\n",
      "        Date  DayOfWeek  TubeJourneyCount  BusJourneyCount         t1  \\\n",
      "0 2022-01-01   Saturday            973000          1787000  13.808333   \n",
      "1 2022-01-02     Sunday           1119000          2135000  11.750000   \n",
      "2 2022-01-03     Monday           1121000          2413000   9.941667   \n",
      "3 2022-01-04    Tuesday           1491000          3351000   5.704167   \n",
      "4 2022-01-05  Wednesday           1686000          3819000   3.412500   \n",
      "\n",
      "          t2        hum  wind_speed           weather  \n",
      "0  13.808333  82.880417   20.137500  Partially cloudy  \n",
      "1  11.516667  83.035833   21.654167  Partially cloudy  \n",
      "2   8.645833  81.815000   17.616667  Partially cloudy  \n",
      "3   2.900000  83.017917   13.841667  Partially cloudy  \n",
      "4   0.066667  76.649167   15.183333             Clear  \n",
      "Sample UK Bank Holiday Dates: [datetime.date(2022, 5, 2), datetime.date(2022, 12, 26), datetime.date(2021, 5, 3), datetime.date(2022, 6, 3), datetime.date(2026, 4, 6)]\n",
      "Final merged daily data with additional features:\n",
      "        Date  DayOfWeek  TubeJourneyCount  BusJourneyCount         t1  \\\n",
      "0 2022-01-01   Saturday            973000          1787000  13.808333   \n",
      "1 2022-01-02     Sunday           1119000          2135000  11.750000   \n",
      "2 2022-01-03     Monday           1121000          2413000   9.941667   \n",
      "3 2022-01-04    Tuesday           1491000          3351000   5.704167   \n",
      "4 2022-01-05  Wednesday           1686000          3819000   3.412500   \n",
      "5 2022-01-06   Thursday           1690000          3890000   2.987500   \n",
      "6 2022-01-07     Friday           1821000          4066000   4.387500   \n",
      "7 2022-01-08   Saturday           1532000          2918000   6.395833   \n",
      "8 2022-01-09     Sunday           1161000          2383000   4.579167   \n",
      "9 2022-01-10     Monday           1717000          4012000   5.933333   \n",
      "\n",
      "          t2        hum  wind_speed           weather  is_holiday  is_weekend  \\\n",
      "0  13.808333  82.880417   20.137500  Partially cloudy           0           1   \n",
      "1  11.516667  83.035833   21.654167  Partially cloudy           0           1   \n",
      "2   8.645833  81.815000   17.616667  Partially cloudy           1           0   \n",
      "3   2.900000  83.017917   13.841667  Partially cloudy           0           0   \n",
      "4   0.066667  76.649167   15.183333             Clear           0           0   \n",
      "5   0.620833  86.894583   12.495833  Partially cloudy           0           0   \n",
      "6   0.458333  81.038333   20.000000  Partially cloudy           0           0   \n",
      "7   3.500000  89.407917   18.116667  Partially cloudy           0           1   \n",
      "8   1.879167  81.861250   12.600000             Clear           0           1   \n",
      "9   5.054167  93.448333    6.704167  Partially cloudy           0           0   \n",
      "\n",
      "   season  TubeJourneyCount_lag1  BusJourneyCount_lag1  \n",
      "0       3               973000.0             1787000.0  \n",
      "1       3               973000.0             1787000.0  \n",
      "2       3              1119000.0             2135000.0  \n",
      "3       3              1121000.0             2413000.0  \n",
      "4       3              1491000.0             3351000.0  \n",
      "5       3              1686000.0             3819000.0  \n",
      "6       3              1690000.0             3890000.0  \n",
      "7       3              1821000.0             4066000.0  \n",
      "8       3              1532000.0             2918000.0  \n",
      "9       3              1161000.0             2383000.0  \n",
      "Tube data sample:\n",
      "        Date  DayOfWeek  TubeJourneyCount  TubeJourneyCount_lag1         t1  \\\n",
      "0 2022-01-01   Saturday            973000               973000.0  13.808333   \n",
      "1 2022-01-02     Sunday           1119000               973000.0  11.750000   \n",
      "2 2022-01-03     Monday           1121000              1119000.0   9.941667   \n",
      "3 2022-01-04    Tuesday           1491000              1121000.0   5.704167   \n",
      "4 2022-01-05  Wednesday           1686000              1491000.0   3.412500   \n",
      "\n",
      "          t2        hum  wind_speed           weather  is_holiday  is_weekend  \\\n",
      "0  13.808333  82.880417   20.137500  Partially cloudy           0           1   \n",
      "1  11.516667  83.035833   21.654167  Partially cloudy           0           1   \n",
      "2   8.645833  81.815000   17.616667  Partially cloudy           1           0   \n",
      "3   2.900000  83.017917   13.841667  Partially cloudy           0           0   \n",
      "4   0.066667  76.649167   15.183333             Clear           0           0   \n",
      "\n",
      "   season  \n",
      "0       3  \n",
      "1       3  \n",
      "2       3  \n",
      "3       3  \n",
      "4       3  \n",
      "\n",
      "Bus data sample:\n",
      "        Date  DayOfWeek  BusJourneyCount  BusJourneyCount_lag1         t1  \\\n",
      "0 2022-01-01   Saturday          1787000             1787000.0  13.808333   \n",
      "1 2022-01-02     Sunday          2135000             1787000.0  11.750000   \n",
      "2 2022-01-03     Monday          2413000             2135000.0   9.941667   \n",
      "3 2022-01-04    Tuesday          3351000             2413000.0   5.704167   \n",
      "4 2022-01-05  Wednesday          3819000             3351000.0   3.412500   \n",
      "\n",
      "          t2        hum  wind_speed           weather  is_holiday  is_weekend  \\\n",
      "0  13.808333  82.880417   20.137500  Partially cloudy           0           1   \n",
      "1  11.516667  83.035833   21.654167  Partially cloudy           0           1   \n",
      "2   8.645833  81.815000   17.616667  Partially cloudy           1           0   \n",
      "3   2.900000  83.017917   13.841667  Partially cloudy           0           0   \n",
      "4   0.066667  76.649167   15.183333             Clear           0           0   \n",
      "\n",
      "   season  \n",
      "0       3  \n",
      "1       3  \n",
      "2       3  \n",
      "3       3  \n",
      "4       3  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_30696\\1259243180.py:109: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_daily['TubeJourneyCount_lag1'] = merged_daily['TubeJourneyCount_lag1'].fillna(method='bfill')\n",
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_30696\\1259243180.py:110: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_daily['BusJourneyCount_lag1'] = merged_daily['BusJourneyCount_lag1'].fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------\n",
    "# Part A: Process Weather Data\n",
    "# ---------------------------\n",
    "# Load the hourly weather data file\n",
    "weather_file = \"raw-data/london_weather_2022_2023_2024.csv\"  # Update as needed\n",
    "weather_df = pd.read_csv(weather_file)\n",
    "\n",
    "# Convert the DateTime column to datetime\n",
    "weather_df['DateTime'] = pd.to_datetime(weather_df['DateTime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Create a new column for just the date\n",
    "weather_df['date_only'] = weather_df['DateTime'].dt.date\n",
    "\n",
    "# Define a helper function for mode (most frequent value)\n",
    "def mode_series(x):\n",
    "    return x.mode().iloc[0] if not x.mode().empty else np.nan\n",
    "\n",
    "# Aggregate the hourly weather data to daily values\n",
    "daily_weather = weather_df.groupby('date_only').agg({\n",
    "    't1': 'mean',\n",
    "    't2': 'mean',\n",
    "    'hum': 'mean',\n",
    "    'wind_speed': 'mean',\n",
    "    'weather': mode_series\n",
    "}).reset_index()\n",
    "\n",
    "# Rename the grouping column to 'Date'\n",
    "daily_weather = daily_weather.rename(columns={'date_only': 'Date'})\n",
    "\n",
    "# Convert 'Date' to datetime (so it matches journey data)\n",
    "daily_weather['Date'] = pd.to_datetime(daily_weather['Date'])\n",
    "print(\"Daily weather sample:\")\n",
    "print(daily_weather.head())\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Part B: Process Journey Data\n",
    "# ---------------------------\n",
    "journey_file_2022_2023_2024 = \"combined-rider-data.csv\"\n",
    "journey_data = pd.read_csv(journey_file_2022_2023_2024) \n",
    "\n",
    "# (If not already done, convert TravelDate to datetime.)\n",
    "journey_data['TravelDate'] = pd.to_datetime(journey_data['TravelDate'])\n",
    "print(\"Journey data sample:\")\n",
    "print(journey_data.head())\n",
    "\n",
    "# ---------------------------\n",
    "# Part C: Merge Journey and Weather Data (Daily)\n",
    "# ---------------------------\n",
    "# Rename TravelDate to \"Date\" for merging\n",
    "journey_data = journey_data.rename(columns={'TravelDate': 'Date'})\n",
    "\n",
    "# Merge journey data (daily) with daily weather data on \"Date\"\n",
    "merged_daily = pd.merge(journey_data, daily_weather, on='Date', how='left')\n",
    "print(\"Merged daily data sample:\")\n",
    "print(merged_daily.head())\n",
    "\n",
    "# ---------------------------\n",
    "# Part D: Feature Engineering\n",
    "# ---------------------------\n",
    "# 1. Create is_holiday feature using UK bank holidays.\n",
    "bank_holidays_url = 'https://www.gov.uk/bank-holidays.json'\n",
    "response = requests.get(bank_holidays_url)\n",
    "if response.status_code == 200:\n",
    "    holidays_json = response.json()\n",
    "    # Use holidays for England and Wales\n",
    "    events = holidays_json['england-and-wales']['events']\n",
    "    holiday_dates = {pd.to_datetime(event['date']).date() for event in events}\n",
    "    print(\"Sample UK Bank Holiday Dates:\", list(holiday_dates)[:5])\n",
    "else:\n",
    "    print(\"Error fetching bank holiday data:\", response.status_code)\n",
    "    holiday_dates = set()\n",
    "\n",
    "# Create is_holiday column: 1 if the date is a holiday, else 0\n",
    "merged_daily['is_holiday'] = merged_daily['Date'].dt.date.apply(lambda x: 1 if x in holiday_dates else 0)\n",
    "\n",
    "# 2. Create is_weekend feature:\n",
    "# We already have DayOFWeek from journey_data; you could also compute from Date.\n",
    "# Let's create a new binary flag: 1 if Saturday or Sunday, else 0.\n",
    "merged_daily['is_weekend'] = merged_daily['DayOfWeek'].apply(lambda d: 1 if d.strip().lower() in ['saturday', 'sunday'] else 0)\n",
    "\n",
    "# 3. Create season feature based on the month.\n",
    "def assign_season(dt):\n",
    "    month = dt.month\n",
    "    if month in [3,4,5]:\n",
    "        return 0  # spring\n",
    "    elif month in [6,7,8]:\n",
    "        return 1  # summer\n",
    "    elif month in [9,10,11]:\n",
    "        return 2  # fall\n",
    "    else:\n",
    "        return 3  # winter\n",
    "\n",
    "merged_daily['season'] = merged_daily['Date'].apply(assign_season)\n",
    "\n",
    "# # 4. Create lag features for journey counts.\n",
    "# # For each journey type, create a lag of 1 day.\n",
    "# merged_daily = merged_daily.sort_values('Date').reset_index(drop=True)\n",
    "# merged_daily['TubeJourneyCount_lag1'] = merged_daily['TubeJourneyCount'].shift(1)\n",
    "# merged_daily['BusJourneyCount_lag1'] = merged_daily['BusJourneyCount'].shift(1)\n",
    "\n",
    "# # Optionally, fill missing lag values (the very first day)\n",
    "# merged_daily['TubeJourneyCount_lag1'] = merged_daily['TubeJourneyCount_lag1'].fillna(method='bfill')\n",
    "# merged_daily['BusJourneyCount_lag1'] = merged_daily['BusJourneyCount_lag1'].fillna(method='bfill')\n",
    "\n",
    "print(\"Final merged daily data with additional features:\")\n",
    "print(merged_daily.head(10))\n",
    "\n",
    "# ---------------------------\n",
    "# Part E: Create Separate DataFrames for Tube and Bus Models\n",
    "# ---------------------------\n",
    "tube_data = merged_daily[['Date', 'DayOfWeek', 'TubeJourneyCount',  \n",
    "                            't1', 't2', 'hum', 'wind_speed', 'weather', 'is_holiday', 'is_weekend', 'season']].copy()\n",
    "\n",
    "bus_data = merged_daily[['Date', 'DayOfWeek', 'BusJourneyCount',\n",
    "                           't1', 't2', 'hum', 'wind_speed', 'weather', 'is_holiday', 'is_weekend', 'season']].copy()\n",
    "\n",
    "# Display a sample for each\n",
    "print(\"Tube data sample:\")\n",
    "print(tube_data.head())\n",
    "print(\"\\nBus data sample:\")\n",
    "print(bus_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "028e4a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the  DataFrame with additional features to CSV for later use\n",
    "tube_data.to_csv(\"tube_daily_data.csv\", index=False)\n",
    "bus_data.to_csv(\"bus_daily_data.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
